RELEASE NOTES FOR DAWN 1.7.1 'Duck Hawk'


1. Use the '-data' switch to specify a different workspace if the disk access at your facility
   is slow or restricted in the default location. 
   For instance: dawn -data /scratch/dawn_workspace

2. Toolbar actions on linux can be hidden using the plotting. If the part becomes small, instead 
   of wrapping, some toolbar actions disappear. They can normally be found on the menu to the 
   right of the toolbar (the white down arrow).

3. To reliably find the Dawn version you are using go to:
   * Help->About Dawn.



Workflows:
---------------

1. Workflows are not supported on Windows XP, 32-bit.

2. Workflows do not support Jython actors.

3. If using the .zip download version of Dawn, on Linux 32: It is sometimes necessary to delete 
   the 'jre' folder from the install location. This is due to file permissions. 
   Try doing this if your version does not work on linux and you installed it from a .zip file.

4. If using workflows at Diamond using 'module load dawn/beta' they may not run. In this case do the following:
   * Try to run a workflow, get a cryptic error about the "jre".
   * Open the run configuration 'WorkflowConfiguration' go to the runtime jre setting and click on 'installed jres...'
   * Define a jre with the location on linux64 at Diamond of '/dls_sw/apps/java/x64/jdk1.6.0_38/jre' for linux 64-bit.

5. On windows the firewall can sometimes block the workflow which brings up a windows firewall dialog 
   and stops the workflow from working. If this happens allow the connection and restart the workflow.

6. If you try to run a workflow from a workspace path with spaces, the run/debug configuration 
   has to be changed to include quotes around the model path: -Dmodel="${workspace_loc}${selected_resource_path}" 

 Alternatively you can start dawn with a different workspace path 'dawn -data <another path>' one 
 without spaces in the path. Edna actors usually do not work with spaces in the run path.

7. When using the Python actor in the workflows, you must declare something for 'Dataset Outputs'. 
   If you do not read information back into the workflow, create a dummy variable for this.
